<div align="center">

# ğŸš€ Parallel and Concurrent Programming

### *Master the Art of High-Performance Computing*

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)
[![C++](https://img.shields.io/badge/C++-11+-00599C.svg)](https://isocpp.org/)
[![JavaScript](https://img.shields.io/badge/JavaScript-ES6+-F7DF1E.svg)](https://www.javascript.com/)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

*Unlock the full potential of modern hardware with comprehensive guides, practical examples, and hands-on exercises*

![Programmer Thinking with Threads](https://user-images.githubusercontent.com/37275728/220352641-fb9487f6-e2a6-4433-943d-fffef4141c02.jpeg)

[ğŸ“š Documentation](#learning-path) â€¢ [ğŸ’» Code Examples](#code-examples) â€¢ [ğŸ¯ Quizzes](#interactive-quizzes) â€¢ [ğŸ¤ Contributing](#contributing)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Core Concepts](#-core-concepts)
- [Learning Path](#-learning-path)
- [Code Examples](#-code-examples)
- [Interactive Quizzes](#-interactive-quizzes)
- [Performance Analysis](#-performance-analysis)
- [Practical Applications](#-practical-applications)
- [Getting Started](#-getting-started)
- [Essential Resources](#-essential-resources)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸŒŸ Overview

Parallel and concurrent programming unlock the full potential of modern hardware, enabling applications to perform multiple tasks simultaneously. While these concepts might seem intimidating at first, understanding their fundamentals is crucial for building efficient, responsive software that can handle today's computational demands.

**What you'll learn:**
- ğŸ”„ Design and implement concurrent systems
- âš¡ Write high-performance parallel algorithms
- ğŸ”§ Master multithreading and multiprocessing
- ğŸŒ Build distributed computing applications
- ğŸ“Š Analyze and optimize performance
- ğŸ® Leverage GPU computing capabilities

## ğŸ§  Core Concepts

Understanding parallel and concurrent programming begins with grasping the distinction between these approaches and sequential programming:

| Concept | Description | Key Characteristic |
|---------|-------------|-------------------|
| **Sequential Programming** | Executes instructions one after another in a single thread | Single path of execution |
| **Concurrent Programming** | Manages multiple tasks that may overlap in time | Dealing with lots of things at once |
| **Parallel Programming** | Executes multiple tasks simultaneously across multiple cores | Doing lots of things at once |

> ğŸ’¡ **Key Insight**: Concurrency is about *structure* (dealing with multiple tasks), while parallelism is about *execution* (running multiple tasks simultaneously).

### Quick Example

```python
# Sequential: Tasks run one after another
task1()
task2()
task3()

# Concurrent: Tasks can overlap in time
async def concurrent_execution():
    await asyncio.gather(task1(), task2(), task3())

# Parallel: Tasks run simultaneously on different cores
with multiprocessing.Pool() as pool:
    pool.map(process_task, [task1, task2, task3])
```

## ğŸ“š Learning Path

Progress through these topics to build a comprehensive understanding of parallel and concurrent programming:

| # | Topic | Focus Area | Difficulty | Resource |
|---|-------|------------|------------|----------|
| 1ï¸âƒ£ | **Foundations** | Basic terminology, processes vs threads, synchronization primitives | ğŸŸ¢ Beginner | [Basic Terminology](notes/01_basic_terminology.md) |
| 2ï¸âƒ£ | **Multithreading** | Thread creation, management, synchronization, and safety patterns | ğŸŸ¢ Beginner | [Multithreading](notes/02_multithreading.md) |
| 3ï¸âƒ£ | **Multiprocessing** | Process management, inter-process communication, shared memory | ğŸŸ¡ Intermediate | [Multiprocessing](notes/03_multiprocessing.md) |
| 4ï¸âƒ£ | **Async Programming** | Event loops, async/await patterns, non-blocking I/O operations | ğŸŸ¡ Intermediate | [Asynchronous Programming](notes/04_asynchronous_programming.md) |
| 5ï¸âƒ£ | **Distributed Computing** | Message Passing Interface (MPI), cluster computing, communication patterns | ğŸ”´ Advanced | [MPI Programming](notes/05_mpi.md) |
| 6ï¸âƒ£ | **Hardware Architecture** | Multi-core systems, memory hierarchies, GPU computing, performance considerations | ğŸŸ¡ Intermediate | [Hardware Foundations](notes/06_hardware.md) |
| 7ï¸âƒ£ | **Performance Evaluation** | Benchmarking, profiling, Amdahl's Law, speedup analysis | ğŸ”´ Advanced | [Evaluating Performance](notes/07_evaluating_performance.md) |
| 8ï¸âƒ£ | **Parallel Design** | Design patterns, algorithms, load balancing, scalability | ğŸ”´ Advanced | [Designing Parallel Programs](notes/08_designing_parallel_programs.md) |
| 9ï¸âƒ£ | **GPU Programming** | CUDA, OpenCL, GPU architectures, kernel optimization | ğŸ”´ Advanced | [GPU Programming](notes/09_gpu_programming.md) |

### ğŸ¯ Recommended Learning Sequence

```mermaid
graph LR
    A[Foundations] --> B[Multithreading]
    A --> C[Multiprocessing]
    B --> D[Async Programming]
    C --> D
    D --> E[Distributed Computing]
    A --> F[Hardware Architecture]
    F --> G[Performance Evaluation]
    E --> H[Parallel Design]
    G --> H
    F --> I[GPU Programming]
```

## ğŸ’» Code Examples

This repository includes practical implementations in multiple programming languages:

### ğŸ“ Repository Structure

```
src/
â”œâ”€â”€ ğŸ python/          # Python implementations
â”‚   â”œâ”€â”€ mpi/           # MPI examples (14+ examples)
â”‚   â”œâ”€â”€ asynchrony/    # Async/await patterns
â”‚   â”œâ”€â”€ threads/       # Threading examples
â”‚   â””â”€â”€ processes/     # Multiprocessing examples
â”‚
â”œâ”€â”€ âš™ï¸ cpp/             # C++ implementations
â”‚   â”œâ”€â”€ threads/       # POSIX threads, std::thread
â”‚   â”œâ”€â”€ parallel/      # OpenMP, TBB examples
â”‚   â””â”€â”€ cuda/          # GPU programming
â”‚
â””â”€â”€ ğŸŸ¨ js/              # JavaScript/Node.js
    â”œâ”€â”€ async/         # Promises, async/await
    â”œâ”€â”€ workers/       # Web Workers
    â””â”€â”€ cluster/       # Node.js clustering
```

### ğŸ”¥ Featured Examples

<details>
<summary><b>ğŸ”„ MPI - Parallel Matrix Multiplication</b></summary>

Distributed matrix multiplication using Message Passing Interface:
```python
# Example: Parallel computation across multiple processes
mpiexec -n 4 python src/python/mpi/parallel_matrix_multiplication.py
```
</details>

<details>
<summary><b>âš¡ Async - Parallel Web Fetching</b></summary>

Asynchronous HTTP requests with modern async/await:
```python
# Example: Fetch multiple URLs concurrently
python src/python/asynchrony/fetch_parallel.py
```
</details>

<details>
<summary><b>ğŸ§µ Multithreading - Producer-Consumer</b></summary>

Classic synchronization pattern with thread-safe queues:
```python
# Example: Thread coordination with locks and conditions
python src/python/threads/producer_consumer.py
```
</details>

### ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/djeada/Parallel-And-Concurrent-Programming.git
cd Parallel-And-Concurrent-Programming

# Run Python examples
python src/python/asynchrony/async_generator.py

# Run C++ examples (requires compilation)
g++ -pthread src/cpp/threads/basic_thread.cpp -o thread_demo
./thread_demo

# Run JavaScript examples
node src/js/async/promises_example.js
```

## ğŸ¯ Interactive Quizzes

Test your understanding with interactive quizzes for each topic:

| Quiz | Topic | Questions | Link |
|------|-------|-----------|------|
| ğŸ“ | Basic Terminology | Processes, threads, synchronization | [Quiz 1](quizzes/01_basic_terminology.md) |
| ğŸ“ | Threading Concepts | Thread safety, deadlocks, race conditions | [Quiz 2](quizzes/02_threading.md) |
| ğŸ“ | Process Management | IPC, shared memory, process pools | [Quiz 3](quizzes/03_processes.md) |
| ğŸ“ | Async Patterns | Event loops, futures, coroutines | [Quiz 4](quizzes/04_async.md) |
| ğŸ“ | Distributed Systems | MPI, communication patterns, synchronization | [Quiz 5](quizzes/05_distributed.md) |
| ğŸ“ | Hardware & Architecture | CPU caches, memory models, NUMA | [Quiz 6](quizzes/06_hardware.md) |
| ğŸ“ | Performance Analysis | Benchmarking, profiling, optimization | [Quiz 7](quizzes/07_performance.md) |
| ğŸ“ | Parallel Design Patterns | Algorithms, load balancing, scalability | [Quiz 8](quizzes/08_parallel_design.md) |

## ğŸ“Š Performance Analysis

Explore performance evaluation tools and scripts:

### Available Analysis Scripts

| Script | Description | Concepts |
|--------|-------------|----------|
| ğŸ¯ [Amdahl's Law](scripts/amdahls_law/) | Calculate theoretical speedup limits | Maximum speedup with parallel portions |
| ğŸ¯ [Gustafson's Law](scripts/gustafsons_law/) | Scaled speedup analysis | Speedup with increasing problem size |
| ğŸ“ˆ [Speedup Efficiency](scripts/speedup_efficiency/) | Measure parallel efficiency | Strong vs weak scaling |
| ğŸ”„ [Communication Overhead](scripts/communication_overhead/) | Analyze synchronization costs | Network latency, bandwidth impact |
| ğŸ§© [Granularity Analysis](scripts/granularity_analysis/) | Task size optimization | Fine-grained vs coarse-grained parallelism |
| ğŸ’¾ [Memory Bandwidth](scripts/memory_bandwidth/) | Memory system performance | Cache effects, bandwidth limitations |

### Performance Metrics

```python
# Example: Calculate speedup and efficiency
speedup = sequential_time / parallel_time
efficiency = speedup / number_of_processors
parallel_overhead = parallel_time - (sequential_time / number_of_processors)
```

## ğŸ¯ Practical Applications

These concepts apply across various domains:

| Domain | Use Cases | Technologies |
|--------|-----------|--------------|
| ğŸŒ **Web Development** | â€¢ Concurrent user request handling<br>â€¢ Database connection pooling<br>â€¢ Real-time data processing | Node.js cluster, async/await, Web Workers |
| ğŸ”¬ **Scientific Computing** | â€¢ Parallel simulations<br>â€¢ Data processing pipelines<br>â€¢ Numerical analysis | MPI, OpenMP, NumPy, SciPy |
| ğŸ® **Game Development** | â€¢ Physics calculations<br>â€¢ AI processing<br>â€¢ Rendering pipelines | Multi-threading, SIMD, GPU compute |
| ğŸ“Š **Data Science** | â€¢ Parallel data processing<br>â€¢ Distributed machine learning<br>â€¢ ETL pipelines | Dask, Ray, Spark, parallel pandas |
| ğŸ’» **System Programming** | â€¢ Operating system kernels<br>â€¢ Device drivers<br>â€¢ Network protocols | POSIX threads, async I/O, kernel threads |
| ğŸ¤– **Machine Learning** | â€¢ Model training parallelization<br>â€¢ Hyperparameter tuning<br>â€¢ Inference optimization | TensorFlow, PyTorch, CUDA, distributed training |
| ğŸ“± **Mobile Development** | â€¢ Background task processing<br>â€¢ Image processing<br>â€¢ Network operations | Coroutines, GCD, async patterns |

## ğŸš€ Getting Started

### Prerequisites

Before diving into parallel and concurrent programming, ensure you have:

- âœ… Basic programming knowledge in Python, C++, or JavaScript
- âœ… Understanding of algorithms and data structures
- âœ… Familiarity with command-line tools
- âœ… Development environment set up for your chosen language

### Learning Strategy

```
ğŸ“– Read Theory â†’ ğŸ’» Write Code â†’ ğŸ§ª Run Examples â†’ ğŸ“Š Analyze Performance â†’ ğŸ”„ Iterate
```

1. **ğŸ¯ Start with the basics**
   - Understand processes, threads, and synchronization
   - Learn about race conditions and deadlocks
   - Study synchronization primitives (locks, semaphores, barriers)

2. **ğŸ’¡ Practice with simple examples**
   - Implement basic producer-consumer patterns
   - Create thread-safe data structures
   - Experiment with different synchronization techniques

3. **ğŸ”§ Explore language-specific tools**
   - Python: `threading`, `multiprocessing`, `asyncio`
   - C++: `std::thread`, OpenMP, TBB
   - JavaScript: Promises, async/await, Web Workers

4. **ğŸ—ï¸ Build real projects**
   - Apply concepts to actual problems
   - Measure and optimize performance
   - Learn from mistakes and edge cases

5. **ğŸ“ˆ Study performance**
   - Profile your code with appropriate tools
   - Understand Amdahl's and Gustafson's laws
   - Optimize based on measurements, not assumptions

### ğŸ› ï¸ Tools and Environment Setup

<details>
<summary><b>Python Setup</b></summary>

```bash
# Install MPI for distributed computing
sudo apt-get install mpich
pip install mpi4py

# Install async libraries
pip install aiohttp asyncio

# Performance profiling
pip install line_profiler memory_profiler
```
</details>

<details>
<summary><b>C++ Setup</b></summary>

```bash
# Install compiler with C++11 support
sudo apt-get install g++ cmake

# Install OpenMP (usually included with GCC)
# Install Intel TBB
sudo apt-get install libtbb-dev

# CUDA for GPU programming
# Download from NVIDIA website
```
</details>

<details>
<summary><b>JavaScript Setup</b></summary>

```bash
# Install Node.js
curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
sudo apt-get install -y nodejs

# Install useful packages
npm install -g clinic autocannon
```
</details>

## ğŸ“š Essential Resources

### ğŸ“– Books and Documentation

| Resource | Focus | Level |
|----------|-------|-------|
| [Operating Systems Concepts](https://www.personal.kent.edu/~rmuhamma/OpSystems/os.html) | Foundational OS knowledge | ğŸŸ¢ Beginner |
| [The Art of Computer Programming](https://www.oreilly.com/library/view/the-art-of/9780596802424/) | Algorithmic foundations | ğŸ”´ Advanced |
| [Asynchronous Programming with C++](https://www.packtpub.com/) | Modern C++ async patterns | ğŸŸ¡ Intermediate |

### ğŸ“ Academic Resources

| Resource | Institution | Topics |
|----------|-------------|--------|
| [Parallel Programming Bootcamp](https://princetonuniversity.github.io/PUbootcamp/sessions/parallel-programming/) | Princeton University | Comprehensive parallel programming |
| [CS152 Computer Architecture](https://inst.eecs.berkeley.edu/~cs152/fa16/lectures/) | UC Berkeley | Hardware architecture insights |
| [Concurrent Systems](https://w3.cs.jmu.edu/kirkpams/OpenCSF/Books/csf/html/) | JMU | Systems programming perspective |

### ğŸ”§ Language-Specific Resources

<details>
<summary><b>ğŸ Python Resources</b></summary>

- [Understanding Python Asyncio](https://lucumr.pocoo.org/2016/10/30/i-dont-understand-asyncio/) - Deep dive into async
- [Raymond's PyBay Keynote](https://pybay.com/site_media/slides/raymond2017-keynote/index.html) - Concurrency insights
- [Python Threading Documentation](https://docs.python.org/3/library/threading.html) - Official docs
- [Multiprocessing Guide](https://docs.python.org/3/library/multiprocessing.html) - Process-based parallelism
</details>

<details>
<summary><b>âš™ï¸ C++ Resources</b></summary>

- [C++ Concurrency in Action](https://www.manning.com/books/c-plus-plus-concurrency-in-action) - Comprehensive guide
- [OpenMP Tutorial](https://computing.llnl.gov/tutorials/openMP/) - Parallel programming API
- [Intel TBB Documentation](https://www.threadingbuildingblocks.org/) - Threading library
</details>

<details>
<summary><b>ğŸŸ¨ JavaScript Resources</b></summary>

- [Node.js Async Patterns](https://www.cs.unb.ca/~bremner/teaching/cs2613/books/nodejs-api/) - Async programming
- [Web Workers API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API) - Browser parallelism
- [Node.js Cluster Module](https://nodejs.org/api/cluster.html) - Multi-process Node.js
</details>

### ğŸ¥ Video Courses & Tutorials

- **Coursera**: Parallel Programming courses from top universities
- **edX**: Distributed Systems and Concurrent Programming
- **YouTube**: Conference talks on concurrency patterns and performance

## ğŸ¤ Contributing

We welcome contributions from developers at all skill levels! Here's how you can help improve this repository:

### ğŸ¯ Ways to Contribute

| Type | Description | Examples |
|------|-------------|----------|
| ğŸ› **Bug Fixes** | Correct errors in code or documentation | Fix race conditions, update broken links |
| ğŸ’¡ **New Examples** | Add implementations in different languages | Add Rust examples, Go implementations |
| âš¡ **Performance Improvements** | Optimize existing code samples | Better algorithms, reduce overhead |
| ğŸ“ **Documentation** | Clarify explanations or add concepts | Improve clarity, add diagrams |
| ğŸ§ª **Tests & Quizzes** | Add test cases or quiz questions | Unit tests, integration tests |
| ğŸ¨ **Visualizations** | Create diagrams or animations | Thread synchronization diagrams |

### ğŸ“‹ Contribution Guidelines

1. **ğŸ´ Fork the Repository**
   ```bash
   git clone https://github.com/YOUR_USERNAME/Parallel-And-Concurrent-Programming.git
   cd Parallel-And-Concurrent-Programming
   ```

2. **ğŸŒ¿ Create a Feature Branch**
   ```bash
   git checkout -b feature/your-feature-name
   # or
   git checkout -b fix/your-bugfix-name
   ```

3. **âœ¨ Make Your Changes**
   - Write clean, documented code
   - Follow existing code style and conventions
   - Add comments explaining complex logic
   - Test your changes thoroughly

4. **âœ… Test Your Code**
   ```bash
   # Python
   python -m pytest tests/
   
   # C++
   make test
   
   # JavaScript
   npm test
   ```

5. **ğŸ“ Commit with Clear Messages**
   ```bash
   git add .
   git commit -m "Add: Brief description of your changes"
   # Use prefixes: Add, Fix, Update, Refactor, Docs
   ```

6. **ğŸš€ Submit a Pull Request**
   - Push your branch to GitHub
   - Open a PR with a detailed description
   - Reference any related issues
   - Wait for review and address feedback

### ğŸ’¬ Discussion and Support

- **ğŸ’¡ Have an idea?** Open an issue to discuss before implementing
- **â“ Need help?** Check existing issues or create a new one
- **ğŸ› Found a bug?** Report it with reproduction steps
- **ğŸ“– Improving docs?** Just submit a PR!

### ğŸŒŸ Code Style Guidelines

- **Python**: Follow PEP 8, use type hints where appropriate
- **C++**: Follow Google C++ Style Guide, use modern C++11/14/17 features
- **JavaScript**: Use ESLint, prefer ES6+ features
- **Comments**: Explain *why*, not *what* (code should be self-explanatory)

### âœ… Pull Request Checklist

Before submitting your PR, ensure:

- [ ] Code follows the repository's style guidelines
- [ ] All tests pass successfully
- [ ] Documentation is updated (if applicable)
- [ ] Commit messages are clear and descriptive
- [ ] No merge conflicts with main branch
- [ ] Changes are focused and minimal

### ğŸ† Recognition

Contributors will be recognized in our [Contributors List](https://github.com/djeada/Parallel-And-Concurrent-Programming/graphs/contributors). Significant contributions may be highlighted in release notes!

## â“ FAQ & Troubleshooting

<details>
<summary><b>Q: When should I use threads vs processes?</b></summary>

**Threads** are better for:
- I/O-bound tasks
- Shared memory requirements
- Lower overhead

**Processes** are better for:
- CPU-bound tasks
- Isolation requirements
- Avoiding Global Interpreter Lock (Python)
</details>

<details>
<summary><b>Q: How do I prevent race conditions?</b></summary>

Use synchronization primitives:
- **Locks/Mutexes**: Mutual exclusion for critical sections
- **Semaphores**: Control access to limited resources
- **Atomic operations**: Lock-free synchronization
- **Immutable data**: Avoid shared mutable state
</details>

<details>
<summary><b>Q: My parallel code is slower than sequential. Why?</b></summary>

Common causes:
- **Overhead**: Thread/process creation and synchronization costs
- **Amdahl's Law**: Sequential portions limit speedup
- **False sharing**: Cache line contention
- **I/O bottlenecks**: Disk/network limitations
- **Too fine-grained**: Tasks too small relative to overhead
</details>

<details>
<summary><b>Q: How many threads/processes should I use?</b></summary>

General guidelines:
- **CPU-bound**: Number of CPU cores (or cores - 1)
- **I/O-bound**: Can be much higher (10x, 100x cores)
- **Mixed workloads**: Profile and experiment
- Use `os.cpu_count()` (Python) or similar to detect cores
</details>

## ğŸ“Š Repository Statistics

![GitHub Stars](https://img.shields.io/github/stars/djeada/Parallel-And-Concurrent-Programming?style=social)
![GitHub Forks](https://img.shields.io/github/forks/djeada/Parallel-And-Concurrent-Programming?style=social)
![GitHub Issues](https://img.shields.io/github/issues/djeada/Parallel-And-Concurrent-Programming)
![GitHub Pull Requests](https://img.shields.io/github/issues-pr/djeada/Parallel-And-Concurrent-Programming)
![Last Commit](https://img.shields.io/github/last-commit/djeada/Parallel-And-Concurrent-Programming)

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License - Free to use, modify, and distribute
âœ… Commercial use
âœ… Modification
âœ… Distribution
âœ… Private use
```

Feel free to use this content for learning, teaching, or building your own projects!

---

<div align="center">

## ğŸŒŸ Show Your Support

If you find this repository helpful, please consider:

â­ **Starring** this repository
ğŸ”— **Sharing** with others who might benefit
ğŸ¤ **Contributing** your own examples and improvements
ğŸ’¬ **Discussing** in issues and pull requests

### ğŸ“ˆ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=djeada/Parallel-And-Concurrent-Programming&type=Date)](https://star-history.com/#djeada/Parallel-And-Concurrent-Programming&Date)

---

**Made with â¤ï¸ by the community** | **Happy Parallel Programming!** ğŸš€

[â¬† Back to Top](#-parallel-and-concurrent-programming)

</div>
